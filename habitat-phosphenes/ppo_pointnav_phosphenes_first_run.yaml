habitat:
  dataset:
    content_scenes:
    - '*'
    data_path: data/datasets/pointnav/gibson/v1/{split}/{split}.json.gz
    scenes_dir: data/scene_datasets
    split: train
    type: PointNav-v1
  env_task: GymHabitatEnv
  env_task_gym_dependencies: []
  env_task_gym_id: ''
  environment:
    iterator_options:
      cycle: true
      group_by_scene: true
      max_scene_repeat_episodes: -1
      max_scene_repeat_steps: 10000
      num_episode_sample: -1
      shuffle: true
      step_repetition_range: 0.2
    max_episode_seconds: 10000000
    max_episode_steps: 500
  gym:
    achieved_goal_keys: []
    action_keys: null
    desired_goal_keys: []
    obs_keys: null
  seed: 100
  simulator:
    ac_freq_ratio: 4
    action_space_config: v0
    action_space_config_arguments: {}
    additional_object_paths: []
    agents:
      main_agent:
        articulated_agent_type: FetchRobot
        articulated_agent_urdf: data/robots/hab_fetch/robots/hab_fetch.urdf
        grasp_managers: 1
        height: 1.5
        ik_arm_urdf: data/robots/hab_fetch/robots/fetch_onlyarm.urdf
        is_set_start_state: false
        joint_start_noise: 0.1
        motion_data_path: ''
        radius: 0.1
        sim_sensors:
          depth_sensor:
            height: 256
            hfov: 90
            max_depth: 10.0
            min_depth: 0.0
            noise_model: None
            noise_model_kwargs: {}
            normalize_depth: true
            orientation:
            - 0.0
            - 0.0
            - 0.0
            position:
            - 0.0
            - 1.25
            - 0.0
            sensor_subtype: PINHOLE
            type: HabitatSimDepthSensor
            width: 256
          rgb_sensor:
            height: 256
            hfov: 90
            noise_model: None
            noise_model_kwargs: {}
            orientation:
            - 0.0
            - 0.0
            - 0.0
            position:
            - 0.0
            - 1.25
            - 0.0
            sensor_subtype: PINHOLE
            type: HabitatSimRGBSensor
            width: 256
        start_position:
        - 0.0
        - 0.0
        - 0.0
        start_rotation:
        - 0.0
        - 0.0
        - 0.0
        - 1.0
    agents_order:
    - main_agent
    auto_sleep: false
    concur_render: false
    create_renderer: false
    ctrl_freq: 120.0
    debug_render: false
    debug_render_articulated_agent: false
    debug_render_goal: true
    default_agent_id: 0
    ep_info: null
    forward_step_size: 0.25
    grasp_impulse: 10000.0
    habitat_sim_v0:
      allow_sliding: true
      enable_gfx_replay_save: false
      enable_physics: false
      frustum_culling: true
      gpu_device_id: 0
      gpu_gpu: false
      leave_context_with_background_renderer: false
      physics_config_file: ./data/default.physics_config.json
    hold_thresh: 0.15
    kinematic_mode: false
    load_objs: false
    needs_markers: true
    object_ids_start: 100
    requires_textures: true
    robot_joint_start_noise: 0.0
    scene: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    scene_dataset: default
    seed: 100
    step_physics: true
    tilt_angle: 15
    turn_angle: 10
    type: Sim-v0
    update_articulated_agent: true
  task:
    actions:
      move_forward:
        agent_index: 0
        type: MoveForwardAction
      stop:
        agent_index: 0
        type: StopAction
      turn_left:
        agent_index: 0
        type: TurnLeftAction
      turn_right:
        agent_index: 0
        type: TurnRightAction
    art_succ_thresh: 0.15
    base_angle_noise: 0.523599
    base_noise: 0.05
    cache_robot_init: false
    constraint_violation_drops_object: false
    constraint_violation_ends_episode: true
    count_obj_collisions: true
    desired_resting_position:
    - 0.5
    - 0.0
    - 1.0
    ee_exclude_region: 0.0
    ee_sample_factor: 0.2
    enable_safe_drop: false
    end_on_success: true
    filter_nav_to_tasks: []
    force_regenerate: false
    goal_sensor_uuid: pointgoal_with_gps_compass
    joint_max_impulse: -1.0
    lab_sensors:
      pointgoal_with_gps_compass_sensor:
        dimensionality: 2
        goal_format: POLAR
        type: PointGoalWithGPSCompassSensor
    measurements:
      distance_to_goal:
        distance_to: POINT
        type: DistanceToGoal
      distance_to_goal_reward:
        type: DistanceToGoalReward
      spl:
        type: SPL
      success:
        success_distance: 0.2
        type: Success
    min_start_distance: 3.0
    num_spawn_attempts: 200
    obj_succ_thresh: 0.3
    object_in_hand_sample_prob: 0.167
    pddl_domain_def: replica_cad
    physics_stability_steps: 1
    render_target: true
    reward_measure: distance_to_goal_reward
    robot_at_thresh: 2.0
    settle_steps: 5
    should_enforce_target_within_reach: false
    should_save_to_cache: false
    slack_reward: -0.01
    spawn_max_dist_to_obj: 2.0
    spawn_region_scale: 0.2
    success_measure: spl
    success_reward: 2.5
    success_state: 0.0
    task_spec: ''
    task_spec_base_path: habitat/task/rearrange/pddl/
    type: Nav-v0
    use_marker_t: true
habitat_baselines:
  checkpoint_folder: data/checkpoints
  checkpoint_interval: -1
  distrib_updater_name: DDPPO
  eval:
    evals_per_ep: 1
    extra_sim_sensors: {}
    should_load_ckpt: true
    split: val
    use_ckpt_config: true
    video_option: []
  eval_ckpt_path_dir: data/checkpoints
  eval_keys_to_include_in_name: []
  evaluate: false
  force_blind_policy: false
  force_torch_single_threaded: false
  load_resume_state_config: true
  log_file: train.log
  log_interval: 10
  num_checkpoints: 10
  num_environments: 16
  num_processes: -1
  num_updates: 10000
  profiling:
    capture_start_step: -1
    num_steps_to_capture: -1
  rl:
    agent:
      type: SingleAgentAccessMgr
    auxiliary_losses: {}
    ddppo:
      backbone: resnet18
      distrib_backend: GLOO
      force_distributed: false
      num_recurrent_layers: 1
      pretrained: false
      pretrained_encoder: false
      pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
      reset_critic: true
      rnn_type: GRU
      sync_frac: 0.6
      train_encoder: true
    policy:
      action_dist:
        action_activation: tanh
        clamp_std: true
        log_std_init: 0.0
        max_log_std: 2
        max_std: 1
        min_log_std: -5
        min_std: 1.0e-06
        scheduled_std: false
        std_init: ???
        use_log_std: true
        use_softplus: false
        use_std_param: false
      action_distribution_type: categorical
      hierarchical_policy: ???
      name: PointNavResNetPolicy
      obs_transforms:
        EdgeFilter:
          sigma: 3
          threshold_high: 40
          threshold_low: 20
          type: EdgeFilter
        GrayScale:
          type: GrayScale
        Phosphenes:
          resolution: 32
          sigma: 2
          size:
          - 256
          - 256
          type: Phosphenes
    ppo:
      clip_param: 0.2
      entropy_coef: 0.01
      entropy_target_factor: 0.0
      eps: 1.0e-05
      gamma: 0.99
      hidden_size: 512
      lr: 0.00025
      max_grad_norm: 0.5
      num_mini_batch: 2
      num_steps: 5
      ppo_epoch: 4
      reward_window_size: 50
      tau: 0.95
      use_adaptive_entropy_pen: false
      use_clipped_value_loss: true
      use_double_buffered_sampler: false
      use_gae: true
      use_linear_clip_decay: false
      use_linear_lr_decay: false
      use_normalized_advantage: false
      value_loss_coef: 0.5
    preemption:
      append_slurm_job_id: false
      save_resume_state_interval: 100
      save_state_batch_only: false
    ver:
      num_inference_workers: 2
      overlap_rollouts_and_learn: false
      variable_experience: true
  rollout_storage_name: RolloutStorage
  tensorboard_dir: tb
  test_episode_count: -1
  torch_gpu_id: 0
  total_num_steps: -1.0
  trainer_name: ppo
  updater_name: PPO
  verbose: true
  video_dir: video_dir
  video_fps: 10
  wb:
    entity: ''
    group: ''
    project_name: ''
    run_name: ''
  writer_type: tb
